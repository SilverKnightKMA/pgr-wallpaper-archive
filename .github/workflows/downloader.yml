name: PGR Wallpapers Downloader

on:
  schedule:
    - cron: '0 0 * * 0'
  workflow_dispatch:
    inputs:
      max_images:
        description: 'Maximum number of images allowed before triggering downloader.'
        required: false
        default: 10000

jobs:
  scrape-and-download:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    outputs:
      has_new_images: ${{ steps.check_new.outputs.has_new }}
      release_tag: ${{ steps.set_tag.outputs.tag }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        with:
          ref: main
          fetch-depth: 1

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: 18
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Install ImageMagick
        run: sudo apt-get update && sudo apt-get install -y imagemagick

      - name: Ensure branches exist
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: bash src/init_branches.sh

      - name: Load existing image manifest for comparison
        run: |
          mkdir -p data
          SERVERS=$(node -e "const c=require('./config.json'); c.servers.forEach(s => console.log(s.id))")
          if [ -f "data/manifest.json" ]; then
            while IFS= read -r id; do
              mkdir -p "branches/$id"
              python3 src/prepare_manifest.py "$id" > "branches/$id/.existing_images"
            done <<< "$SERVERS"
          else
            while IFS= read -r id; do mkdir -p "branches/$id"; done <<< "$SERVERS"
          fi

      - name: Scrape Links
        env:
          MAX_IMAGES: ${{ inputs.max_images }}
        run: node src/scraper.js

      - name: Retry broken links
        run: |
          SERVERS=$(node -e "const c=require('./config.json'); c.servers.forEach(s => console.log(s.id))")
          while IFS= read -r id; do
            if [ -s "Wallpapers/failed/${id}.txt" ]; then
              grep -vxFf "Wallpapers/images_url/${id}.txt" "Wallpapers/failed/${id}.txt" >> "Wallpapers/images_url/${id}.txt" || true
            fi
          done <<< "$SERVERS"

      - name: Download Wallpapers
        shell: pwsh
        run: ./src/downloader.ps1

      - name: Organize Images & Generate Thumbnails
        run: |
          SERVERS=$(node -e "const c=require('./config.json'); c.servers.forEach(s => console.log(s.id))")
          THUMB_WIDTH=$(node -e "const c=require('./config.json'); console.log(c.settings.thumbnailWidth || 400)")
          
          while IFS= read -r id; do
            if [ -d "branches/$id" ]; then
              # Move images
              mkdir -p "branches/$id/images"
              find "branches/$id" -maxdepth 1 -type f \( -iname '*.jpg' -o -iname '*.jpeg' -o -iname '*.png' -o -iname '*.webp' \) -exec mv {} "branches/$id/images/" \;
              
              # Generate Thumbnails
              if [ -d "branches/$id/images" ]; then
                bash src/generate_thumbnails.sh "branches/$id/images" "$THUMB_WIDTH"
                # Organize thumbnails
                if [ -d "branches/$id/images/thumbnails" ]; then
                  mkdir -p "branches/$id/thumbnails"
                  find "branches/$id/images/thumbnails" -maxdepth 1 -type f -exec mv {} "branches/$id/thumbnails/" \;
                  rmdir "branches/$id/images/thumbnails" 2>/dev/null || true
                fi
              fi
            fi
          done <<< "$SERVERS"

      - name: Check for new images
        id: check_new
        run: |
          new_count=0
          SERVERS=$(node -e "const c=require('./config.json'); c.servers.forEach(s => console.log(s.id))")
          while IFS= read -r id; do
            txt="Wallpapers/images_url/${id}.txt"
            if [ -f "$txt" ] && [ -s "$txt" ]; then
              new_count=$((new_count + $(wc -l < "$txt")))
            fi
          done <<< "$SERVERS"
          echo "New images found: $new_count"
          echo "has_new=$([ "$new_count" -gt 0 ] && echo "true" || echo "false")" >> "$GITHUB_OUTPUT"

      - name: Set release tag
        id: set_tag
        if: steps.check_new.outputs.has_new == 'true'
        run: |
          TAG="wallpapers-$(date -u +%Y%m%d-%H%M%S)"
          echo "tag=$TAG" >> "$GITHUB_OUTPUT"
          TAG_TS=$(echo "$TAG" | sed 's/wallpapers-\([0-9]\{4\}\)\([0-9]\{2\}\)\([0-9]\{2\}\)-\([0-9]\{2\}\)\([0-9]\{2\}\)\([0-9]\{2\}\)/\1-\2-\3T\4:\5:\6Z/')
          echo "timestamp=$TAG_TS" >> "$GITHUB_OUTPUT"

      - name: Sync Repo (Push Images & Previews)
        if: steps.check_new.outputs.has_new == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RELEASE_TAG_TS: ${{ steps.set_tag.outputs.timestamp }}
        run: bash src/sync_repo.sh

      - name: Update main README
        if: steps.check_new.outputs.has_new == 'true'
        run: |
          MANIFEST_PATH="$(pwd)/data/manifest.json" node src/generate_readme.js main
          if [ ! -f docs/favicon.png ]; then
            curl -sL -o docs/favicon.png "https://cdnstatic.kurogame.net/h5_manage_dist/pgr_website2.0/favicon.png" || true
          fi
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add README.md data/manifest.json
          [ -f docs/favicon.png ] && git add docs/favicon.png
          if ! git diff --cached --quiet; then
            git commit -m "Auto-sync: Update main README and manifest"
            git push
          fi

      - name: Create Release Notes
        if: steps.check_new.outputs.has_new == 'true'
        id: release_notes
        env:
          RELEASE_TAG: ${{ steps.set_tag.outputs.tag }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: python3 src/create_release_body.py

      - name: Zip Assets
        if: steps.check_new.outputs.has_new == 'true' && steps.release_notes.outputs.has_files == 'true'
        run: |
          mkdir -p release_assets
          # Reuse logic to find files to zip
          SERVERS=$(node -e "const c=require('./config.json'); c.servers.forEach(s => console.log(s.id))")
          while IFS= read -r id; do
            mkdir -p "release_staging/$id"
            txt="Wallpapers/images_url/${id}.txt"
            [ -f "$txt" ] && while IFS= read -r url; do
              fn=$(basename "$url")
              decoded=$(python3 -c "import urllib.parse, sys; print(urllib.parse.unquote(sys.argv[1]))" "$fn")
              [ -f "branches/$id/images/$decoded" ] && cp "branches/$id/images/$decoded" "release_staging/$id/"
            done < "$txt"
          done <<< "$SERVERS"
          
          # Simple zip logic (split if needed)
          cd release_staging
          zip -r "../release_assets/${{ steps.set_tag.outputs.tag }}.zip" .
          # Note: If you need the complex splitting logic, put it in a separate src/zip_assets.sh script too!

      - name: Create GitHub Release
        if: steps.check_new.outputs.has_new == 'true' && steps.release_notes.outputs.has_files == 'true'
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.set_tag.outputs.tag }}
          name: "Wallpapers ${{ steps.set_tag.outputs.tag }}"
          body_path: release_notes.md
          files: release_assets/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
