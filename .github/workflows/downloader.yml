name: PGR Wallpapers Downloader

on:
  schedule:
    - cron: '0 0 * * 0'
  workflow_dispatch:
    inputs:
      max_images:
        description: 'Maximum number of images to scrape per server (not counting existing images).'
        required: false
        default: 10000

jobs:
  scrape-and-download:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        with:
          ref: main
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Python Dependencies
        run: pip install Pillow

      - name: Ensure branches exist
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: bash src/init_branches.sh

      - name: Load existing image manifest for comparison
        run: |
          mkdir -p data
          SERVERS=$(python3 -c "import json; c=json.load(open('config.json')); [print(s['id']) for s in c['servers']]")
          if [ -f "data/manifest.json" ]; then
            while IFS= read -r id; do
              mkdir -p "branches/$id"
              python3 src/prepare_manifest.py "$id" > "branches/$id/.existing_images"
            done <<< "$SERVERS"
          else
            while IFS= read -r id; do mkdir -p "branches/$id"; done <<< "$SERVERS"
          fi

      - name: Scrape Links
        env:
          MAX_IMAGES: ${{ inputs.max_images }}
        run: python3 src/scraper.py

      - name: Retry broken links
        run: |
          SERVERS=$(python3 -c "import json; c=json.load(open('config.json')); [print(s['id']) for s in c['servers']]")
          while IFS= read -r id; do
            if [ -s "Wallpapers/failed/${id}.txt" ]; then
              grep -vxFf "Wallpapers/images_url/${id}.txt" "Wallpapers/failed/${id}.txt" >> "Wallpapers/images_url/${id}.txt" 2>/dev/null || true
            fi
          done <<< "$SERVERS"

      - name: Check for new images
        id: check_new
        run: |
          has_new=false
          SERVERS=$(python3 -c "import json; c=json.load(open('config.json')); [print(s['id']) for s in c['servers']]")
          while IFS= read -r id; do
            txt="Wallpapers/images_url/${id}.txt"
            if [ -f "$txt" ] && [ -s "$txt" ]; then
              count=$(wc -l < "$txt")
              echo "New images for $id: $count"
              has_new=true
            fi
          done <<< "$SERVERS"
          echo "has_new=$has_new" >> "$GITHUB_OUTPUT"

      - name: Download, Process & Release (Batched Loop)
        if: steps.check_new.outputs.has_new == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          set -e

          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          BATCH=0
          MORE_WORK=true

          while $MORE_WORK; do
            BATCH=$((BATCH + 1))
            echo ""
            echo "========================================"
            echo "  BATCH $BATCH"
            echo "========================================"
            # --- Disk diagnostics ---
            echo "--- Disk Usage ---"
            df -h / | tail -1
            echo "Top space consumers:"
            du -sh /tmp/* 2>/dev/null | sort -rh | head -5 || true
            du -sh branches/* 2>/dev/null | sort -rh | head -5 || true
            du -sh .git 2>/dev/null || true
            echo "------------------"
            # --- Set release tag for this batch ---
            RELEASE_TAG="wallpapers-$(date -u +%Y%m%d-%H%M%S)"
            RELEASE_TAG_TS=$(echo "$RELEASE_TAG" | sed 's/wallpapers-\([0-9]\{4\}\)\([0-9]\{2\}\)\([0-9]\{2\}\)-\([0-9]\{2\}\)\([0-9]\{2\}\)\([0-9]\{2\}\)/\1-\2-\3T\4:\5:\6Z/')
            export RELEASE_TAG RELEASE_TAG_TS

            # --- 1. Download (up to 1.8GB) ---
            echo "--- Step 1: Download ---"
            DL_EXIT=0
            python3 -u src/downloader.py || DL_EXIT=$?

            if [ "$DL_EXIT" -eq 2 ]; then
              echo "Batch limit reached -- will loop again after processing."
            elif [ "$DL_EXIT" -ne 0 ]; then
              echo "Downloader failed with exit code $DL_EXIT"
              exit 1
            else
              MORE_WORK=false
            fi

            # Check if any files were actually downloaded
            DOWNLOAD_COUNT=$(find branches/*/downloads/ -type f 2>/dev/null | wc -l)
            if [ "$DOWNLOAD_COUNT" -eq 0 ]; then
              echo "No files downloaded in this batch. Stopping."
              break
            fi
            echo "Downloaded $DOWNLOAD_COUNT files in batch $BATCH"

            # --- 2. Process images (resolution + previews) ---
            echo "--- Step 2: Process Images ---"
            python3 -u src/process_images.py

            # --- 3. Save old manifest ---
            if [ -f data/manifest.json ]; then
              cp data/manifest.json data/manifest_old.json
            else
              echo '{}' > data/manifest_old.json
            fi

            # --- 4. Sync repo (push wallpapers + previews) ---
            echo "--- Step 3: Sync Repo ---"
            bash src/sync_repo.sh

            # --- 5. Diff manifests ---
            echo "--- Step 4: Diff Manifests ---"
            mkdir -p new_images
            python3 src/diff_manifest.py data/manifest_old.json data/manifest.json new_images

            # --- 6. Update main README ---
            echo "--- Step 5: Update README ---"
            MANIFEST_PATH="$(pwd)/data/manifest.json" python3 src/generate_readme.py main
            if [ ! -f docs/favicon.png ]; then
              curl -sL -o docs/favicon.png "https://cdnstatic.kurogame.net/h5_manage_dist/pgr_website2.0/favicon.png" || true
            fi
            git add README.md data/manifest.json
            [ -f docs/favicon.png ] && git add docs/favicon.png
            if ! git diff --cached --quiet; then
              git commit -m "Auto-sync: Update README and manifest (batch $BATCH)"
              git push
            fi

            # --- 7. Create release ---
            echo "--- Step 6: Release ---"
            python3 src/create_release_body.py

            # Check if there are files to release
            HAS_NEW_FILES=$(find new_images/ -name '*.txt' -not -empty 2>/dev/null | head -1)
            if [ -n "$HAS_NEW_FILES" ]; then
              gh release create "$RELEASE_TAG" \
                --title "$RELEASE_TAG" \
                --notes-file release_notes.md

              bash src/zip_and_release.sh "$RELEASE_TAG"
            else
              echo "No new files to release in batch $BATCH."
            fi

            # --- 8. Cleanup for next batch ---
            echo "--- Step 7: Cleanup ---"
            # Delete ALL files created during this loop iteration
            SERVERS=$(python3 -c "import json; c=json.load(open('config.json')); [print(s['id']) for s in c['servers']]")
            while IFS= read -r id; do
              # Remove everything under each server branch dir (downloads, images, previews, etc.)
              rm -rf "branches/$id/downloads" "branches/$id/images" "branches/$id/previews"
              # Remove any other temp files in server branch dirs
              find "branches/$id" -type f -delete 2>/dev/null || true
            done <<< "$SERVERS"
            rm -rf new_images Wallpapers/downloaded Wallpapers/failed
            rm -f release_notes.md data/manifest_old.json data/image_metadata.json

            # Clean up any leftover temp git repos from sync_repo.sh (mktemp dirs)
            rm -rf /tmp/tmp.*/repo_wp /tmp/tmp.*/repo_pv 2>/dev/null || true
            # Remove empty mktemp parent dirs
            find /tmp -maxdepth 1 -type d -empty -name 'tmp.*' -delete 2>/dev/null || true

            # Prune main repo git objects to free space
            git gc --prune=now --aggressive 2>/dev/null || true
            git prune 2>/dev/null || true

            echo "Disk after cleanup:"
            df -h / | tail -1

            echo "Batch $BATCH complete."
            echo ""

            # Small delay between batches to avoid rate limiting
            if $MORE_WORK; then
              sleep 5
            fi
          done

          echo ""
          echo "========================================"
          echo "  ALL BATCHES COMPLETE"
          echo "========================================"
